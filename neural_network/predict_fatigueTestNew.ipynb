{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доступные устройства: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import mediapipe as mp\n",
    "import threading\n",
    "import os\n",
    "\n",
    "\n",
    "# Инициализация MediaPipe Face Mesh с использованием GPU\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "# Проверка доступности GPU\n",
    "print(\"Доступные устройства:\", tf.config.list_physical_devices())\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Ограничение памяти GPU для предотвращения утечек\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        print(\"Используется GPU:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Загрузка модели\n",
    "model = keras.models.load_model(os.path.join('..', 'neural_network', 'data', 'models', 'my_test_model.keras'))\n",
    "\n",
    "class VideoProcessor:\n",
    "    def __init__(self):\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.set_resolution(640, 480)\n",
    "        self.lock = threading.Lock()\n",
    "        self.frame = None\n",
    "        self.running = True\n",
    "        self.prediction = None\n",
    "        self.face_detected = False\n",
    "\n",
    "    def set_resolution(self, width, height):\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "        self.cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "\n",
    "    def capture_frames(self):\n",
    "        while self.running:\n",
    "            ret, frame = self.cap.read()\n",
    "            if ret:\n",
    "                with self.lock:\n",
    "                    self.frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    def process_frames(self):\n",
    "        while self.running:\n",
    "            if self.frame is None:\n",
    "                continue\n",
    "            \n",
    "            # Копирование кадра для обработки\n",
    "            with self.lock:\n",
    "                frame_copy = self.frame.copy()\n",
    "            \n",
    "            # Обнаружение лиц с MediaPipe (GPU-оптимизировано)\n",
    "            results = face_mesh.process(frame_copy)\n",
    "            \n",
    "            if results.multi_face_landmarks:\n",
    "                self.face_detected = True\n",
    "                # Получение ограничивающего прямоугольника лица\n",
    "                h, w, _ = frame_copy.shape\n",
    "                landmarks = results.multi_face_landmarks[0].landmark\n",
    "                x_coords = [int(lm.x * w) for lm in landmarks]\n",
    "                y_coords = [int(lm.y * h) for lm in landmarks]\n",
    "                x1, x2 = min(x_coords), max(x_coords)\n",
    "                y1, y2 = min(y_coords), max(y_coords)\n",
    "                \n",
    "                # Выделение области лица с запасом\n",
    "                expansion = 50\n",
    "                x1 = max(0, x1 - expansion)\n",
    "                y1 = max(0, y1 - expansion)\n",
    "                x2 = min(w, x2 + expansion)\n",
    "                y2 = min(h, y2 + expansion)\n",
    "                \n",
    "                # Предобработка для модели\n",
    "                face_roi = frame_copy[y1:y2, x1:x2]\n",
    "                if face_roi.size == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Конвертация в тензор и предсказание\n",
    "                input_tensor = tf.convert_to_tensor(\n",
    "                    [cv2.resize(face_roi, (145, 145)) / 255.0],\n",
    "                    dtype=tf.float32\n",
    "                )\n",
    "                \n",
    "                # Асинхронное предсказание на GPU\n",
    "                self.prediction = model(input_tensor, training=False)[0][0].numpy()\n",
    "            else:\n",
    "                self.face_detected = False\n",
    "\n",
    "    def run(self):\n",
    "        # Запуск потоков\n",
    "        capture_thread = threading.Thread(target=self.capture_frames)\n",
    "        process_thread = threading.Thread(target=self.process_frames)\n",
    "        \n",
    "        capture_thread.start()\n",
    "        process_thread.start()\n",
    "        \n",
    "        while self.running:\n",
    "            if self.frame is None:\n",
    "                continue\n",
    "            \n",
    "            # Отрисовка результатов\n",
    "            with self.lock:\n",
    "                display_frame = cv2.cvtColor(self.frame, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            if self.face_detected and self.prediction is not None:\n",
    "                status = \"FATIGUE\" if self.prediction > 0.7 else \"ACTIVE\"\n",
    "                color = (0, 0, 255) if status == \"FATIGUE\" else (0, 255, 0)\n",
    "                cv2.putText(display_frame, f\"{status} {self.prediction:.2f}\", \n",
    "                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "            \n",
    "            # Показать FPS\n",
    "            fps = self.cap.get(cv2.CAP_PROP_FPS)\n",
    "            cv2.putText(display_frame, f\"FPS: {fps:.1f}\", (10, 60),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            \n",
    "            cv2.imshow('Fatigue Detection', display_frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == 27:\n",
    "                self.running = False\n",
    "        \n",
    "        # Очистка\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        capture_thread.join()\n",
    "        process_thread.join()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processor = VideoProcessor()\n",
    "    processor.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
